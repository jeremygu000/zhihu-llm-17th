{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e76bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1223e77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表: {'hotel': 0, 'room': 2, 'price': 1, 'service': 3}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"hotel room price\",  # 文档1\n",
    "    \"service hotel\"      # 文档2  \n",
    "]\n",
    "\n",
    "vec = CountVectorizer(stop_words=list(ENGLISH_STOP_WORDS))\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "print(\"词汇表:\", vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e362741",
   "metadata": {},
   "source": [
    "vec.vocabulary_ 中的词汇是按照字母顺序排列的。\n",
    "\n",
    "为什么是这样？\n",
    "\n",
    "1. 默认行为：CountVectorizer 和 TfidfVectorizer 默认会按词汇的字母顺序对特征进行排序， 内部使用 sorted(vocabulary) 来确定特征顺序。\n",
    "2. 一致性：这样确保了每次运行都得到相同的特征顺序， 字母排序让结果在不同运行中可复现。\n",
    "3. 可预测性：便于后续的模型处理和解释， 统一顺序对模型训练和解释特征重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42613b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量化结果:\n",
      "[[1 1 1 0]\n",
      " [1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"向量化结果:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a2575",
   "metadata": {},
   "source": [
    "详细解释：\n",
    "\n",
    "第一行 [1 1 1 0] 对应词汇表顺序：\n",
    "  - 索引0: 'hotel' → 文档1包含，所以是1\n",
    "  - 索引1: 'room'  → 文档1包含，所以是1  \n",
    "  - 索引2: 'price' → 文档1包含，所以是1\n",
    "  - 索引3: 'service' → 文档1不包含，所以是0\n",
    "\n",
    "第二行 [1 0 0 1] 对应词汇表顺序：\n",
    "  - 索引0: 'hotel' → 文档2包含，所以是1ß\n",
    "  - 索引1: 'room'  → 文档2不包含，所以是0\n",
    "  - 索引2: 'price' → 文档2不包含，所以是0\n",
    "  - 索引3: 'service' → 文档2包含，所以是1\n",
    "\n",
    "这就是**词袋模型（Bag of Words）模型**的核心思想：将文档表示为词汇表中各个词出现与否的向量，通过计数或二进制标记来表示文档特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efbaea",
   "metadata": {},
   "source": [
    "词袋模型的局限性\n",
    "\n",
    "为什么词袋模型不关心顺序？\n",
    "\n",
    "简单性：只关注词汇的存在与否，不考虑语法和语义\n",
    "计算效率：避免了复杂的序列分析\n",
    "数学基础：基于\"词汇独立假设\"\n",
    "这确实是个问题！\n",
    "\n",
    "```py\n",
    "doc1 = \"I love this hotel room\"\n",
    "doc2 = \"This hotel room I love\"\n",
    "\n",
    "# 两者向量化后可能得到相同的特征向量\n",
    "# 因为都包含：'hotel', 'room', 'love', 'this'\n",
    "# 但语义完全不同！\n",
    "```\n",
    "\n",
    "现代解决方案：\n",
    "\n",
    "使用 n-gram 模型（考虑连续词组）\n",
    "使用 词嵌入（如 Word2Vec, GloVe）\n",
    "使用 上下文模型（如 BERT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b0016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表: {'love': 1, 'hotel': 0, 'room': 2}\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "X1 = vec.fit_transform([\"I love hotel room\", \"love this hotel room\"])\n",
    "print(\"词汇表:\", vec.vocabulary_) # {'love': 1, 'hotel': 0, 'room': 2}, \"this\" & \"I\" are removed\n",
    "print(X1.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhihu-llm-17th",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
